{
  
    
        "post0": {
            "title": "Pandas DataFrames with a GSLIB I/O Methods",
            "content": "def write_gslib(self, filename:str): with open(filename, &quot;w&quot;) as f: f.write(&quot;GSLIB Example Data n&quot;) f.write(f&quot;{len(self._obj.columns)} n&quot;) f.write(&quot; n&quot;.join(self._obj.columns)+&quot; n&quot;) for row in df.itertuples(): row_data = &quot; t&quot;.join([f&quot;{i:.3f}&quot; for i in row[1:]]) f.write(f&quot;{row_data} n&quot;) def read_gslib(filename:str): with open(filename, &quot;r&quot;) as f: lines = f.readlines() ncols = int(lines[1].split()[0]) col_names = [lines[i+2].strip() for i in range(ncols)] df = pd.read_csv(filename, skiprows=ncols+2, delim_whitespace=True, names=col_names) return df . Step 2: pd.DataFrame Accessor . I&#39;m a big fan of this Pandas functionality. Just a simple decorator opens up the ability to add your own methods, properties etc. Here are the steps: . Make a class out your function(s). I&#39;ll call mine . GSLIBAccessor: . | class GSLIBAccessor: def __init__(self, pandas_obj): self._obj=(pandas_obj) def write_gslib(self, filename:str): with open(filename, &quot;w&quot;) as f: f.write(&quot;GSLIB Example Data n&quot;) f.write(f&quot;{len(self._obj.columns)} n&quot;) f.write(&quot; n&quot;.join(self._obj.columns)+&quot; n&quot;) for row in df.itertuples(): row_data = &quot; t&quot;.join([f&quot;{i:.3f}&quot; for i in row[1:]]) f.write(f&quot;{row_data} n&quot;) def read_gslib(filename:str): with open(filename, &quot;r&quot;) as f: lines = f.readlines() ncols = int(lines[1].split()[0]) col_names = [lines[i+2].strip() for i in range(ncols)] df = pd.read_csv(filename, skiprows=ncols+2, delim_whitespace=True, names=col_names) return df . In the __init__ include your DataFrame that this method will be operating on, pandas_obj in above snippet. | Add the decorator (Also I removed the _gslib suffix): | @pd.api.extensions.register_dataframe_accessor(&quot;gslib&quot;) class GSLIBAccessor: def __init__(self, pandas_obj): self._obj=(pandas_obj) def write(self, filename:str): with open(filename, &quot;w&quot;) as f: f.write(&quot;GSLIB Example Data n&quot;) f.write(f&quot;{len(self._obj.columns)} n&quot;) f.write(&quot; n&quot;.join(self._obj.columns)+&quot; n&quot;) for row in df.itertuples(): row_data = &quot; t&quot;.join([f&quot;{i:.3f}&quot; for i in row[1:]]) f.write(f&quot;{row_data} n&quot;) @staticmethod def read(filename:str): with open(filename, &quot;r&quot;) as f: lines = f.readlines() ncols = int(lines[1].split()[0]) col_names = [lines[i+2].strip() for i in range(ncols)] df = pd.read_csv(filename, skiprows=ncols+2, delim_whitespace=True, names=col_names) return df . Boom! Done! Thats it. Fantastic, right? . Now, the functionwrite_gslib is available as a DataFrame method at df.gslib.write() . There are plenty of GSLIB specific details to manage here - fill null values with -999.00, add grid definition in the file header etc, but the point here is this is a fast, easy, flexible way to add whatever functionality you need to the DataFrame class. . Reading in a dataframe by this approach works just fine as well. Keep in mind, the method created is associated with the DataFrame and won&#39;t be accessible at same place as the other pandas I/O operations like pd.read_csv, instead it will be at pd.DataFrame.gslib.read. . df = pd.DataFrame.gslib.read(&quot;data/example.dat&quot;) df.head() . x y z var . 0 0.723 | 0.564 | 0.785 | 2.853 | . 1 0.915 | 0.317 | 0.357 | 0.749 | . 2 0.346 | 0.484 | 0.690 | 0.786 | . 3 0.591 | 0.150 | 0.669 | 0.290 | . 4 0.157 | 0.332 | 0.006 | 1.777 | . To write out the file: . df.gslib.write(&quot;data/export_data.dat&quot;) . with open(&quot;data/export_data.dat&quot;, &quot;r&quot;) as f: for i in range(10): print(f.readline().strip()) . GSLIB Example Data 4 x y z var 0.723 0.564 0.785 2.853 0.915 0.317 0.357 0.749 0.346 0.484 0.690 0.786 0.591 0.150 0.669 0.290 . Step 3: Subclassing Pandas DataFrame . If forwhatever reason the decorator accessor approach isn&#39;t enough, you can always create your own class entirely and inheirit pd.DataFrame. This is a bit more work and there are a couple import details not to be missed. . Inheiritance . Inheiritance is a common aspect of OOP (object oriented programming), and is a topic that warrants a discussion all its own. Rather than get into that can of worms, if want some more details I&#39;d suggest Real Python: Inheiritance and Composition. In example, create a new class and inheirit all the good things that pd.DataFrame does, but add a few properities, methods etc. . class GSLIBDataFrame(pd.DataFrame): def __init__(self, data, *args, **kwargs): super().__init__(data=data, *args, **kwargs) def write(self, filename:str): with open(filename, &quot;w&quot;) as f: f.write(&quot;GSLIB Example Data n&quot;) f.write(f&quot;{len(self._obj.columns)} n&quot;) f.write(&quot; n&quot;.join(self._obj.columns)+&quot; n&quot;) for row in df.itertuples(): row_data = &quot; t&quot;.join([f&quot;{i:.3f}&quot; for i in row[1:]]) f.write(f&quot;{row_data} n&quot;) @classmethod def read(cls, filename:str): with open(filename, &quot;r&quot;) as f: lines = f.readlines() ncols = int(lines[1].split()[0]) col_names = [lines[i+2].strip() for i in range(ncols)] df = pd.read_csv(filename, skiprows=ncols+2, delim_whitespace=True, names=col_names) return cls(df) . This works and is quite similar to the accessor example but I do think this apporach would scale better should you have big plans for your DIY dataframes. Lets consider a couple issues shown below . df = GSLIBDataFrame.read(&quot;data/example.dat&quot;) returned_df = df.applymap(lambda x: x*2) type(returned_df) . pandas.core.frame.DataFrame . If you use some standard pandas operatione, it will return a regular pd.DataFrame not a GSLIBDataFrame - To manage this, the _constructor must be defined to override the method inheirted from pandas. . | Any other properites created, but be added to the metadata list so that they are passed on to results of manipulation. . | To demonstrate in addition to the previously defined methods, add a property favorite_column, though this name is nonsense this can be a useful approach for defining a specific column that defines categories, domains or coordinates. . class GSLIBDataFrame(pd.DataFrame): def __init__(self, data, favorite_column=None, *args, **kwargs): super().__init__(data=data, *args, **kwargs) self.favorite_column = favorite_column _metadata = [&quot;favorite_column&quot;] @property def _constructor(self): return GSLIBDataFrame def write(self, filename:str): with open(filename, &quot;w&quot;) as f: f.write(&quot;GSLIB Example Data n&quot;) f.write(f&quot;{len(self._obj.columns)} n&quot;) f.write(&quot; n&quot;.join(self._obj.columns)+&quot; n&quot;) for row in df.itertuples(): row_data = &quot; t&quot;.join([f&quot;{i:.3f}&quot; for i in row[1:]]) f.write(f&quot;{row_data} n&quot;) @classmethod def read(cls, filename:str, favorite_column:str): with open(filename, &quot;r&quot;) as f: lines = f.readlines() ncols = int(lines[1].split()[0]) col_names = [lines[i+2].strip() for i in range(ncols)] df = pd.read_csv(filename, skiprows=ncols+2, delim_whitespace=True, names=col_names) return cls(data=df, favorite_column=favorite_column) . Now, instead of returning a pd.DataFrame a GSLIBDataFrame is returned as a result of manipulation. . df = GSLIBDataFrame.read(&quot;data/example.dat&quot;, favorite_column=&quot;var&quot;) returned_df = df.applymap(lambda x: x*2) type(returned_df) . __main__.GSLIBDataFrame . Subclassing pd.DataFrame requires a bit more effort and has some quirks but in the long run might be worthwhile in cases where more than just a few methods and/or properites are going to be added to the class. If you&#39;re going down this road, have a look at the Pandas Documentation: Extending Pandas, much of what I shared here is paraphrased from their fantastic documentation. .",
            "url": "geostats.dev/2020/09/16/extending-pandas.html",
            "relUrl": "/2020/09/16/extending-pandas.html",
            "date": " • Sep 16, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Importing and Exporting GSLIB (GEO-EAS) Data with Pandas",
            "content": "import pandas as pd . . def read_gslib(filename:str): with open(filename, &quot;r&quot;) as f: lines = f.readlines() ncols = int(lines[1].split()[0]) col_names = [lines[i+2].strip() for i in range(ncols)] df = pd.read_csv(filename, skiprows=ncols+2, delim_whitespace=True, names=col_names) return df . df = read_gslib(filename=&quot;data/example.dat&quot;) df.head() . x y z var . 0 0.723 | 0.564 | 0.785 | 2.853 | . 1 0.915 | 0.317 | 0.357 | 0.749 | . 2 0.346 | 0.484 | 0.690 | 0.786 | . 3 0.591 | 0.150 | 0.669 | 0.290 | . 4 0.157 | 0.332 | 0.006 | 1.777 | . Now go about your business analyzing data, making plots and doing all the other things python does well until you need re-export to GSLIB to run specific Geostatistical algorithm. . Writing a Pandas DataFrame to GSLIB Format . As with reading in the data, I&#39;m sure there are a number of ways this can be done. Below is one rather simple approach where I write the header than iterate over each row as a tuple. . If speed is a consideration when iterating over a pandas DataFrame use .itertuples its noticeably faster than .iterrows. . def write_gslib(df:pd.DataFrame, filename:str): with open(filename, &quot;w&quot;) as f: f.write(&quot;GSLIB Example Data n&quot;) f.write(f&quot;{len(df.columns)} n&quot;) f.write(&quot; n&quot;.join(df.columns)+&quot; n&quot;) for row in df.itertuples(): row_data = &quot; t&quot;.join([f&quot;{i:.3f}&quot; for i in row[1:]]) f.write(f&quot;{row_data} n&quot;) . write_gslib(df, &quot;data/exported_data.dat&quot;) . Now, just have a quick look at the file to be sure its correct: . with open(&quot;data/exported_data.dat&quot;,&quot;r&quot;) as f: for i in range(10): print(f.readline().strip()) . GSLIB Example Data 4 x y z var 0.723 0.564 0.785 2.853 0.915 0.317 0.357 0.749 0.346 0.484 0.690 0.786 0.591 0.150 0.669 0.290 . Really the whole purpose here is to have these functions readily available to copy/paste when you need them. .",
            "url": "geostats.dev/jupyter/gslib/pandas/geostatistics/python/2020/09/14/pandas-and-gslib.html",
            "relUrl": "/jupyter/gslib/pandas/geostatistics/python/2020/09/14/pandas-and-gslib.html",
            "date": " • Sep 14, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "First Post",
            "content": "Why? . In the last few years I’ve slowly started a list of things that were interesting, challenging or particularly useful that I’ve encountered working with python. The mental list turned into a written list and now a blog for a few reasons. . Its an opportunity to write down some of these tid-bits so I don’t forget them and have a reference next time something similar comes up. | Fastpages looked like a fun low barrier to entry blogging platform that makes it easy to share some code from a notebook, markdown or even a word file. | self-promotion. I’m generally terrible at this but every time I sign up for something new they ask for a github profile or personal website. If you’ve seen my github profile it needs some work… so here we are. | Does the world need another python blog? . Maybe, but probably not. . There are a lot great resources out there for learning python. Even so, I decided to start my own little page on the internet to share a few of the things I’ve learned and what I’m working on. I can’t promise code shared here will be absolutely perfect, but maybe it will be interesting and hopefully it will save you some time if you’re working on something similar. . Geoscience . My academic and professional background is in the geosciences (Geostatistics and Geology) and over the last 10 years I’ve found Python to be an amazing [nearly] do it all tool to automate and improve day to day tasks. My interests in geoscience focused on (but not limited to) subsurface modeling. In most cases this implies some knowledge and a limited amount of data from subsurface and building models to predict whats going in the areas without existing data. . Python . I’m not sure where I heard it, but I was once told “Python is the second best language for everything”, and I think thats true. In many cases there is another tool that might be better suited for a single specific task but as soon as you are connecting a few specific tasks into a larger workflow python outshines the other options as the best tool for the job. Python comes with drawbacks, out of the box it isn’t the fastest language out there but its fun to write, easy to read and has a rapidly growing set of tools for almost anything you can think of. . Goals . My goal is to add a post at least every few weeks. I don’t really want to get into the weeds on Geostatistics (but if thats of interest let me know!), I’d rather share some small ah ha moments and lessons learned the hard way using python. Hopefully these snippets will be useful to others outside of my own little niche in the geoscience world as well. .",
            "url": "geostats.dev/2020/09/13/first-post.html",
            "relUrl": "/2020/09/13/first-post.html",
            "date": " • Sep 13, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi, I’m Eric - Geostatistician &amp; Python Developer. . I started my career as Geologist in the in mining and exploration field. After a bit of numerical modeling and light introduction to Python I continued my studies at the University of Alberta’s Centre for Computational Geostatistics (CCG). My own research with Dr. Clayton Deutsch was focused on Prediction of Local Uncertainty and Localization. . My interest and experience in Python started with utilitarian scripts to string together a few FORTRAN programs. Since then I’ve gained an appreciation for Python and programming in a broader context - Machine Learning, Data Visualization, Reproducible/Shareable Workflows in Jupyter Notebooks and just a touch of Web Dev. .",
          "url": "geostats.dev/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
      ,"page3": {
          "title": "Resources",
          "content": "Learn Python . Real Python - Originally Michael Herman (TestDriven.io) now owned/run by Dan Bader, Real Python provides tutorials in both text, video and course format on all things python. I’ve learned a great deal from Real Python and highly recommend them. . | Talk Python To Me, Audio seems like a strange medium to learn anything code related but trust me this podcast is great. If you’ve got a background in something other than web development/computer science Talk Python To Me is a great way to get exposed to and learn from the wider world of python. Michael Kennedy does a great job. . | . Learn Geostatistics . GeostatsGuy aka Michael Pyrcz is a Professor at the University of Texas at Austin teaching Geostatistics and Machine Learning. Many (maybe all?) of his lectures are available on YouTube and they’re great for everyone beginner to expert. . | LazyModelingCrew This a group of somewhat recent graduates from the Centre for Computational Geostatistics at the University of Alberta. They’ve recently started sharing some easily digestible Geostatistics lessons as blog posts. I especially recommend the variogram focused posts for anyone new to geostats. . | Geostatistics Lessons Thoughtfully put together lessons for some of the more complex aspects of Geostatics. Mostly supported by the Centre for Computational Geostatics at the University of Alberta. . | . Tools, Packages etc for Geostatistics and Geoscience . AR2GAS . First a plug for the product I work on day to day: AR2GAS is c++ backed software with a Python API that can be run on your local machine, on a local cluster or on the cloud for geostatics on a regular or unstructured grid (or even gridless!). I think we’re doing great work and if you’re interested in learning more please reach out. . Open Source Geostatistics . There are a number of open source python packages available for Geostatistics using Python but my experience with them is limited and I can’t speak to how “production ready” they are. At some point I’d like to do a little compare/contrast/benchmark with a few of these. . SGeMS . SGeMS is a GUI based software for Geostatistics created at Stanford University. If you prefer clicking buttons to writing code this is a great option for free software. | . GSLIB . GSLIB is the original Geostatics Library of software created by Clayton Deutsch that has grown over the years. Its not fancy, but it works and you can always script a few programs together with subprocess. | . Python(ish) . The (ish) because a few of these use FORTRAN or C++ for the heavy lifting. . Pygeostat - Supported by Centre for Computational Geostatistics. Note much of the computation relies heavily on GSLIB FORTRAN programs. | GeostatsGuy - Michael Pyrcz’s python package for geostats. There are 2 components, one is pure python the other relies on GSLIB FORTRAN programs. | High Performance Geostatistics Library written in c++ with a python API - looks interesting and they give some benchmarks showing its substantially faster than GSLIB. | . I don’t know much about these other offerings but they have a number of stars on github so there are some people out there using them. . GSTOOls - Last commit 6 months ago.. | SciKit-Gstat - maybe still maintained? Last commit was 5 months ago. | .",
          "url": "geostats.dev/resources/",
          "relUrl": "/resources/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "geostats.dev/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}