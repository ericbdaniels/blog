{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitpygeostatdevconda214fe2f8e703488293b6f095560eab08",
   "display_name": "Python 3.6.10 64-bit ('pygeostat_dev': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Pandas DataFrames with a GSLIB I/O Methods\n",
    "- categories: [Python, Jupyter, Pandas, GSLIB, OOP]\n",
    "- comments: true\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Pandas is everywhere, for good reason. If you are using python to manipulate data, chances are you're using pandas at some point in your workflow. If you are using python with some kind geoscience data changes are you've come across some weird FORTRAN generated file format that was a great idea in the 80s, but is a bit of a hassle for I/O operations. Pandas offers a large number of [read/write methods](https://pandas.pydata.org/pandas-docs/stable/reference/io.html), but occasionally some archaic file format comes along that can be a challenge (MODFLOW anyone?). But don't limit yourself to I/O operations, if there is additional functionality you desire from Pandas, you can extend dataframe, series or index functionality to do just that. If extending existing Pandas objects isn't enough, with a little extra effort and a few important details subclass and make your own DataFrame class.\n",
    "\n",
    "## Step 1:  Reusable Function\n",
    "\n",
    "In the last post about reading/writing GSLIB files, I shared a couple short snippets I use for reading/writing GEO-EAS (GSLIB) files to/from Pandas. As an example, I'll extend pandas to include these convenient read/write operations:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_gslib(self, filename:str):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"GSLIB Example Data\\n\")\n",
    "        f.write(f\"{len(self._obj.columns)}\\n\")\n",
    "        f.write(\"\\n\".join(self._obj.columns)+\"\\n\")\n",
    "        for row in df.itertuples():\n",
    "            row_data = \"\\t\".join([f\"{i:.3f}\" for i in row[1:]])\n",
    "            f.write(f\"{row_data}\\n\")\n",
    "            \n",
    "def read_gslib(filename:str):\n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        ncols = int(lines[1].split()[0])\n",
    "        col_names = [lines[i+2].strip() for i in range(ncols)]\n",
    "    df = pd.read_csv(filename, skiprows=ncols+2, delim_whitespace=True, names=col_names)\n",
    "    return df"
   ]
  },
  {
   "source": [
    "## Step 2: pd.DataFrame Accessor\n",
    "\n",
    "I'm a big fan of this Pandas functionality. Just a simple decorator opens up the ability to add your own methods, properties etc. Here are the steps:\n",
    "\n",
    "1.  Make a class out your function(s). I'll call mine\n",
    "\n",
    "    `GSLIBAccessor`:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSLIBAccessor:\n",
    "    def __init__(self, pandas_obj):\n",
    "        self._obj=(pandas_obj)\n",
    "\n",
    "    def write_gslib(self, filename:str):\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(\"GSLIB Example Data\\n\")\n",
    "            f.write(f\"{len(self._obj.columns)}\\n\")\n",
    "            f.write(\"\\n\".join(self._obj.columns)+\"\\n\")\n",
    "            for row in df.itertuples():\n",
    "                row_data = \"\\t\".join([f\"{i:.3f}\" for i in row[1:]])\n",
    "                f.write(f\"{row_data}\\n\")\n",
    "            \n",
    "    def read_gslib(filename:str):\n",
    "        with open(filename, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            ncols = int(lines[1].split()[0])\n",
    "            col_names = [lines[i+2].strip() for i in range(ncols)]\n",
    "        df = pd.read_csv(filename, \n",
    "                    skiprows=ncols+2, \n",
    "                    delim_whitespace=True, \n",
    "                    names=col_names)\n",
    "        return df"
   ]
  },
  {
   "source": [
    "1. In the `__init__` include your DataFrame that this method will be operating on, `pandas_obj` in above snippet.\n",
    "2. Add the decorator (Also I removed the `_gslib` suffix):\n",
    "    "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pd.api.extensions.register_dataframe_accessor(\"gslib\")\n",
    "class GSLIBAccessor:\n",
    "    def __init__(self, pandas_obj):\n",
    "        self._obj=(pandas_obj)\n",
    "\n",
    "    def write(self, filename:str):\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(\"GSLIB Example Data\\n\")\n",
    "            f.write(f\"{len(self._obj.columns)}\\n\")\n",
    "            f.write(\"\\n\".join(self._obj.columns)+\"\\n\")\n",
    "            for row in df.itertuples():\n",
    "                row_data = \"\\t\".join([f\"{i:.3f}\" for i in row[1:]])\n",
    "                f.write(f\"{row_data}\\n\")\n",
    "                \n",
    "    @staticmethod        \n",
    "    def read(filename:str):\n",
    "        with open(filename, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            ncols = int(lines[1].split()[0])\n",
    "            col_names = [lines[i+2].strip() for i in range(ncols)]\n",
    "        df = pd.read_csv(filename, \n",
    "                    skiprows=ncols+2, \n",
    "                    delim_whitespace=True, \n",
    "                    names=col_names)\n",
    "        return df"
   ]
  },
  {
   "source": [
    "Boom! Done! Thats it. Fantastic, right? \n",
    "\n",
    "Now, the function`write_gslib` is available as a DataFrame method at `df.gslib.write()` . There are plenty of GSLIB specific details to manage here - fill null values with -999.00, add grid definition in the file header etc, but the point here is this is a fast, easy, flexible way to add whatever functionality you need to the DataFrame class. \n",
    "\n",
    "Reading in a dataframe by this approach works just fine as well. Keep in mind, the method created is associated with the DataFrame and won't be accessible at same place as the other pandas I/O operations like `pd.read_csv`, instead it will be at `pd.DataFrame.gslib.read`. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       x      y      z    var\n0  0.723  0.564  0.785  2.853\n1  0.915  0.317  0.357  0.749\n2  0.346  0.484  0.690  0.786\n3  0.591  0.150  0.669  0.290\n4  0.157  0.332  0.006  1.777",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.723</td>\n      <td>0.564</td>\n      <td>0.785</td>\n      <td>2.853</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.915</td>\n      <td>0.317</td>\n      <td>0.357</td>\n      <td>0.749</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.346</td>\n      <td>0.484</td>\n      <td>0.690</td>\n      <td>0.786</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.591</td>\n      <td>0.150</td>\n      <td>0.669</td>\n      <td>0.290</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.157</td>\n      <td>0.332</td>\n      <td>0.006</td>\n      <td>1.777</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "df = pd.DataFrame.gslib.read(\"data/example.dat\")\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "To write out the file:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gslib.write(\"data/export_data.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "GSLIB Example Data\n4\nx\ny\nz\nvar\n0.723\t0.564\t0.785\t2.853\n0.915\t0.317\t0.357\t0.749\n0.346\t0.484\t0.690\t0.786\n0.591\t0.150\t0.669\t0.290\n"
    }
   ],
   "source": [
    "with open(\"data/export_data.dat\", \"r\") as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline().strip())"
   ]
  },
  {
   "source": [
    "## Step 3: Subclassing Pandas DataFrame\n",
    "\n",
    "If forwhatever reason the decorator accessor approach isn't enough, you can always create your own class entirely and inheirit `pd.DataFrame`. This is a bit more work and there are a couple import details not to be missed. \n",
    "\n",
    " ### Inheiritance\n",
    " Inheiritance is a common aspect of OOP (object oriented programming), and is a topic that warrants a discussion all its own. Rather than get into that can of worms, if want some more details I'd suggest [Real Python: Inheiritance and Composition](https://realpython.com/inheritance-composition-python/). In example, create a new class and inheirit all the good things that `pd.DataFrame` does, but add a few properities, methods etc."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSLIBDataFrame(pd.DataFrame):\n",
    "    def __init__(self, data, *args, **kwargs):\n",
    "        super().__init__(data=data, *args, **kwargs)\n",
    "\n",
    "    def write(self, filename:str):\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(\"GSLIB Example Data\\n\")\n",
    "            f.write(f\"{len(self._obj.columns)}\\n\")\n",
    "            f.write(\"\\n\".join(self._obj.columns)+\"\\n\")\n",
    "            for row in df.itertuples():\n",
    "                row_data = \"\\t\".join([f\"{i:.3f}\" for i in row[1:]])\n",
    "                f.write(f\"{row_data}\\n\")\n",
    "\n",
    "    @classmethod        \n",
    "    def read(cls, filename:str):\n",
    "        with open(filename, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            ncols = int(lines[1].split()[0])\n",
    "            col_names = [lines[i+2].strip() for i in range(ncols)]\n",
    "        df = pd.read_csv(filename, \n",
    "                    skiprows=ncols+2, \n",
    "                    delim_whitespace=True, \n",
    "                    names=col_names)\n",
    "        return cls(df)"
   ]
  },
  {
   "source": [
    "This works and is quite similar to the accessor example but I do think this apporach would scale better should you have big plans for your DIY dataframes. Lets consider a couple issues shown below"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "pandas.core.frame.DataFrame"
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "df = GSLIBDataFrame.read(\"data/example.dat\")\n",
    "returned_df = df.applymap(lambda x: x*2)\n",
    "\n",
    "type(returned_df)"
   ]
  },
  {
   "source": [
    "\n",
    "\n",
    "1. If you use some standard pandas operatione, it will return a regular `pd.DataFrame` not a `GSLIBDataFrame` - To manage this, the `_constructor` must be defined to override the method inheirted from pandas.\n",
    "\n",
    "2. Any other properites created, but be added to the `metadata` list so that they are passed on to results of manipulation.\n",
    "\n",
    "To demonstrate in addition to the previously defined methods, add a property `favorite_column`, though this name is nonsense this can be a useful approach for defining a specific column that defines categories, domains or coordinates.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSLIBDataFrame(pd.DataFrame):\n",
    "    def __init__(self, data, favorite_column=None, *args, **kwargs):\n",
    "        super().__init__(data=data, *args, **kwargs)\n",
    "        self.favorite_column = favorite_column\n",
    "\n",
    "    _metadata = [\"favorite_column\"]\n",
    "\n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        return GSLIBDataFrame\n",
    "\n",
    "    def write(self, filename:str):\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(\"GSLIB Example Data\\n\")\n",
    "            f.write(f\"{len(self._obj.columns)}\\n\")\n",
    "            f.write(\"\\n\".join(self._obj.columns)+\"\\n\")\n",
    "            for row in df.itertuples():\n",
    "                row_data = \"\\t\".join([f\"{i:.3f}\" for i in row[1:]])\n",
    "                f.write(f\"{row_data}\\n\")\n",
    "\n",
    "    @classmethod        \n",
    "    def read(cls, filename:str, favorite_column:str):\n",
    "        with open(filename, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            ncols = int(lines[1].split()[0])\n",
    "            col_names = [lines[i+2].strip() for i in range(ncols)]\n",
    "        df = pd.read_csv(filename, \n",
    "                    skiprows=ncols+2, \n",
    "                    delim_whitespace=True, \n",
    "                    names=col_names)\n",
    "        return cls(data=df, favorite_column=favorite_column)\n",
    "\n"
   ]
  },
  {
   "source": [
    "Now, instead of returning a `pd.DataFrame` a `GSLIBDataFrame` is returned as a result of manipulation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "__main__.GSLIBDataFrame"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "df = GSLIBDataFrame.read(\"data/example.dat\", favorite_column=\"var\")\n",
    "returned_df = df.applymap(lambda x: x*2)\n",
    "\n",
    "type(returned_df)"
   ]
  },
  {
   "source": [
    "Subclassing `pd.DataFrame` requires a bit more effort and has some quirks but in the long run might be worthwhile in cases where more than just a few methods and/or properites are going to be added to the class. If you're going down this road, have a look at the [Pandas Documentation: Extending Pandas](https://pandas.pydata.org/pandas-docs/stable/development/extending.html), much of what I shared here is paraphrased from their fantastic documentation.  Code snippets posted as [gists on github](https://gist.github.com/ericbdaniels)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}